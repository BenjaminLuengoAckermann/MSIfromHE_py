{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7682453f",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Traducción a Python de **step_02_train_tumor_normal_classifier_for_deployment.m**\n",
    "\n",
    "Comentarios:\n",
    "\n",
    "- En el código original se usaba la resolución de la red de MatLab (224x224), https://www.mathworks.com/help/deeplearning/ug/pretrained-convolutional-neural-networks.html. Manteniendo el tamaño original de la red, se puede hacer transfer learning.\n",
    "- Se usa ResNet18 de la librería classification_models (https://github.com/qubvel/classification_models)\n",
    "- Se dejan liberadas las 20 últimas capas, como hace el script de MatLab Coincide con el último cambio de tamaño de las salidas intermedias.\n",
    "- Se hace validación cruzada con k-fold para $k=5$. En el armado de los datasets de entrenamiento y test, Kather *et al.* usan uno de los $k$ subconjuntos para entrenamiento y los 4 restantes para test. En este código se invierten las cantidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77a8cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "\n",
    "# Se tuvo que cambiar varios imports en el código de classification_models porque \n",
    "# (parece que) apuntaban a una versión viejas de Keras o tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e540c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_inputPath_str = \"C:\\\\Users\\\\Usuario\\\\Desktop\\\\Real Stuff\\\\2022\\\\Practica Supervisada\\\\Proyecto de Investigacion\\\\dataset\" # parent folder for the data set\n",
    "image_inputPath = pathlib.Path(image_inputPath_str)\n",
    "\n",
    "loadPreviousProgress = False # continue where you stopped before\n",
    "currFn = 'classi3xval' # current filename for saving log files\n",
    "\n",
    "hyperparam = {}\n",
    "hyperparam[\"InitialLearnRate\"] = 1e-5      # initial learning rate\n",
    "hyperparam[\"ValidationFrequency\"] = 150    # check validation performance every N iterations, 500 is 3x per epoch\n",
    "hyperparam[\"ValidationPatience\"] = 10      # wait N times before abort\n",
    "hyperparam[\"L2Regularization\"] = 1e-4      # optimization L2 constraint\n",
    "hyperparam[\"MiniBatchSize\"] = 64           # mini batch size, limited by GPU RAM, default 100 on Titan, 500 on P6000\n",
    "hyperparam[\"MaxEpochs\"] = 150              # max. epochs for training, default 15\n",
    "hyperparam[\"hotLayers\"] = 100              # how many layers from the end are not frozen\n",
    "hyperparam[\"learnRateFactor\"] = 2          # learning rate factor for rewired layers\n",
    "hyperparam[\"ExecutionEnvironment\"] = 'gpu' # environment for training and classification\n",
    "hyperparam[\"PixelRangeShear\"] = 5          # max. shear (in pixels) for image augmenter\n",
    "allHyperparam = list(hyperparam.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96aba24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ADIMUC: 3977 files, min width: 512, max width: 512, min height: 512, max height: 512\n",
      "Class STRMUS: 4000 files, min width: 512, max width: 512, min height: 512, max height: 512\n",
      "Class TUMSTU: 4000 files, min width: 512, max width: 512, min height: 512, max height: 512\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "# Chequeo de cantidad de archivos y tamaño de imágenes\n",
    "for im_class in os.listdir(image_inputPath):\n",
    "    dir_width = []\n",
    "    dir_height = []\n",
    "    file_count = 0\n",
    "    for im_file in os.listdir(str(image_inputPath) + \"\\\\\" + im_class):\n",
    "        file_count = file_count + 1\n",
    "        im = PIL.Image.open(str(image_inputPath) + \"\\\\\" + im_class + \"\\\\\" + im_file)\n",
    "        width, height = im.size\n",
    "        dir_width.append(width)\n",
    "        dir_height.append(height)\n",
    "    print(\"Class \" + im_class + \": \" + str(file_count) + \" files, min width: \" \n",
    "          + str(min(dir_width)) + \", max width: \" + str(max(dir_width)) + \", min height: \" \n",
    "          + str(min(dir_height)) + \", max height: \" + str(max(dir_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c05dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11977 files belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  READ ALL IMAGES\n",
    "\n",
    "img_height = 224 # 512\n",
    "img_width = 224 # 512\n",
    "\n",
    "allImages = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_inputPath,\n",
    "  labels='inferred',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "#   batch_size=hyperparam[\"MiniBatchSize\"]\n",
    "  batch_size=None, # No hay batch\n",
    "  label_mode='categorical'\n",
    "  )\n",
    "allImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3bc3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n",
      "<class 'list'>\n",
      "10\n",
      "<class 'tuple'>\n",
      "<class 'numpy.ndarray'>\n",
      "(224, 224, 3)\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "\n",
    "print(type(allImages))\n",
    "b = allImages.take(10)\n",
    "print(type(b))\n",
    "a = list(b.as_numpy_iterator())\n",
    "\n",
    "print(type(a))\n",
    "print(len(a))\n",
    "print(type(a[0]))\n",
    "print(type(a[0][0]))\n",
    "print(a[0][0].shape)\n",
    "print(a[0][1].shape)\n",
    "print(type(a[0][1]))\n",
    "print(a[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2bbf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "class_names = allImages.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cbb74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADIMUC', 'STRMUS', 'TUMSTU']\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38778d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully LOADED TRAINING images\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = allImages.cardinality().numpy()\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "training_set = allImages.take(train_size)\n",
    "testing_set = allImages.skip(train_size)\n",
    "validation_set = testing_set.skip(test_size)\n",
    "testing_set = testing_set.take(test_size)\n",
    "print('successfully LOADED TRAINING images');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.concatenate([y for x, y in training_set], axis=0)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f40c80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_factor = hyperparam[\"PixelRangeShear\"]/224\n",
    "flip_layer = layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "translation_layer = layers.RandomTranslation(height_factor=hw_factor, width_factor=hw_factor)\n",
    "resizing_layer = layers.Resizing(img_height, img_width)\n",
    "\n",
    "training_set_resized = training_set.map(lambda x, y: (resizing_layer(x), y))\n",
    "testing_set_resized = testing_set.map(lambda x, y: (resizing_layer(x), y))\n",
    "validation_set_resized = validation_set.map(lambda x, y: (resizing_layer(x), y))\n",
    "\n",
    "\n",
    "def preprocess(images, labels):\n",
    "  return preprocess_input(images), labels\n",
    "\n",
    "training_set_prep = training_set_resized.map(preprocess)\n",
    "testing_set_prep = testing_set_resized.map(preprocess)\n",
    "validation_set_prep = validation_set_resized.map(preprocess)\n",
    "\n",
    "\n",
    "def expand_d(images, labels):\n",
    "     return tf.expand_dims(images, axis=0), tf.expand_dims(labels, axis=0)\n",
    "\n",
    "training_set_prep_exp = training_set_prep.map(expand_d)\n",
    "testing_set_prep_exp = testing_set_prep.map(expand_d)\n",
    "validation_set_prep_exp = validation_set_prep.map(expand_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2141bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS AINT NECESSARY\n",
    "if loadPreviousProgress:\n",
    "    loaded_model = pickle.load(open(\"*.mat\", 'rb'))\n",
    "    result = loaded_model.score(X_test, Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd026ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN NETWORK\n",
    "\n",
    "experimentCounter = 0\n",
    "skipCounter = 0\n",
    "allModels = {\"resnet18\"}\n",
    "for initialLearnRate = [5e-6]:\n",
    "    hyperparam[\"InitialLearnRate\"] = initialLearnRate\n",
    "    for hotLayers = [20]:\n",
    "        hyperparam[\"HotLayers\"] = hotLayers\n",
    "        for i = 1:\n",
    "            experimentCounter += 1\n",
    "            nmodel = allModels{i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6a47e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------Entrenamiento para k = 1 --------------\n",
      "\n",
      "Epoch 1/5\n",
      "8383/8383 [==============================] - 3587s 427ms/step - loss: 0.2370 - accuracy: 0.9194 - val_loss: 0.2826 - val_accuracy: 0.8949\n",
      "Epoch 2/5\n",
      "8383/8383 [==============================] - 3017s 359ms/step - loss: 0.0909 - accuracy: 0.9773 - val_loss: 0.1735 - val_accuracy: 0.9355\n",
      "Epoch 3/5\n",
      "8383/8383 [==============================] - 3033s 361ms/step - loss: 0.0545 - accuracy: 0.9858 - val_loss: 0.2187 - val_accuracy: 0.9394\n",
      "Epoch 4/5\n",
      "8383/8383 [==============================] - 3488s 415ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 0.4408 - val_accuracy: 0.7681\n",
      "Epoch 5/5\n",
      "8383/8383 [==============================] - 2970s 354ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.4504 - val_accuracy: 0.8404\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "start = time.time()\n",
    "#for idx in range(1, 6):\n",
    "for idx in range(1, 2):\n",
    "    print(\"\\n--------------Entrenamiento para k = \" + str(idx) + \" --------------\\n\")\n",
    "\n",
    "    trainSet_cache = training_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    testSet_cache = testing_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    trainSet_cache_da = trainSet_cache.map(lambda x, y: (flip_layer(x), y))\n",
    "    trainSet_cache_da = trainSet_cache_da.map(lambda x, y: (translation_layer(x), y))\n",
    "    \n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    model_orig = ResNet18((224, 224, 3), weights='imagenet')\n",
    "    new_layer_output = Dense(len(class_names), activation='softmax', name='predictions')\n",
    "    model = Model(model_orig.input, new_layer_output(model_orig.layers[-3].output))\n",
    "#     model.summary()\n",
    "    ldx = 0\n",
    "    for layer in model.layers:\n",
    "        ldx = ldx + 1\n",
    "        if ldx < 69:\n",
    "            layer.trainable = False\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    ep=5\n",
    "    model.fit(training_set_prep_exp, validation_data=validation_set_prep_exp, epochs=ep, validation_freq=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fefd8eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16136.873936414719\n"
     ]
    }
   ],
   "source": [
    "# No es parte del script\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964172ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALIDA:\n",
    "\n",
    "--------------Entrenamiento para k = 1 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "\n",
    "2022-03-24 12:52:49.697213: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
    "2022-03-24 12:52:50.994749: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
    "\n",
    "9581/9581 [==============================] - 159s 15ms/step - loss: 0.2285 - accuracy: 0.9217 - val_loss: 0.2888 - val_accuracy: 0.8902\n",
    "Epoch 2/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.1032 - accuracy: 0.9715 - val_loss: 0.3152 - val_accuracy: 0.8944\n",
    "Epoch 3/5\n",
    "9581/9581 [==============================] - 121s 13ms/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.4664 - val_accuracy: 0.7884\n",
    "Epoch 4/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.3449 - val_accuracy: 0.8986\n",
    "Epoch 5/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0566 - accuracy: 0.9849 - val_loss: 0.1547 - val_accuracy: 0.9741\n",
    "\n",
    "--------------Entrenamiento para k = 2 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9581/9581 [==============================] - 115s 11ms/step - loss: 0.2326 - accuracy: 0.9192 - val_loss: 0.5439 - val_accuracy: 0.8264\n",
    "Epoch 2/5\n",
    "9581/9581 [==============================] - 86s 9ms/step - loss: 0.0890 - accuracy: 0.9763 - val_loss: 0.2247 - val_accuracy: 0.9265\n",
    "Epoch 3/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.3349 - val_accuracy: 0.9011\n",
    "Epoch 4/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0377 - accuracy: 0.9909 - val_loss: 0.2890 - val_accuracy: 0.9240\n",
    "Epoch 5/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.4071 - val_accuracy: 0.8756\n",
    "\n",
    "--------------Entrenamiento para k = 3 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2544 - accuracy: 0.9092 - val_loss: 3.9616 - val_accuracy: 0.6033\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0737 - accuracy: 0.9795 - val_loss: 0.4025 - val_accuracy: 0.8576\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.4569 - val_accuracy: 0.7971\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 1.1441 - val_accuracy: 0.6372\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.2920 - val_accuracy: 0.9152\n",
    "\n",
    "--------------Entrenamiento para k = 4 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2081 - accuracy: 0.9320 - val_loss: 1.8176 - val_accuracy: 0.4747\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0752 - accuracy: 0.9795 - val_loss: 1.0992 - val_accuracy: 0.7023\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.3079 - val_accuracy: 0.8985\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.4832 - val_accuracy: 0.8234\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.6125 - val_accuracy: 0.7566\n",
    "\n",
    "--------------Entrenamiento para k = 5 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2213 - accuracy: 0.9224 - val_loss: 0.3530 - val_accuracy: 0.8894\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.2126 - val_accuracy: 0.9165\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.6642 - val_accuracy: 0.7937\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 0.4132 - val_accuracy: 0.8501\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 0.1960 - val_accuracy: 0.9286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ffe76d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796/1796 [==============================] - 406s 187ms/step\n",
      "[[1.7060665e-02 9.5512283e-01 2.7816407e-02]\n",
      " [2.6109714e-02 8.7888992e-01 9.5000371e-02]\n",
      " [9.0290391e-04 1.2468483e-04 9.9897242e-01]\n",
      " ...\n",
      " [2.8746810e-03 4.3219537e-04 9.9669313e-01]\n",
      " [2.6618546e-01 3.9426968e-01 3.3954483e-01]\n",
      " [8.8663809e-03 1.9244839e-02 9.7188878e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Deploy\n",
    "predictions = model.predict(testing_set_prep_exp)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00547cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095412598503969"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC Calculus\n",
    "y = np.concatenate([y for x, y in testing_set_prep_exp], axis=0)\n",
    "metrics.roc_auc_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf8caca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://52160456-7064-44d1-897b-aa88bc82d43e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://52160456-7064-44d1-897b-aa88bc82d43e/assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "filename = \"trained_model.sav\"\n",
    "pickle.dump(model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c7864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab12a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27287e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4bab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689e35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4f14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aab5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3350543",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ==================================================================================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "__________________________________________________________________________________________________\n",
    "    Layer (type)                            Output Shape               Param #     Connected to                     \n",
    "   ==================================================================================================\n",
    " 01  data (InputLayer)                     [(None, 224, 224, 3  0)]                []                               \n",
    " 02  bn_data (BatchNormalization)           (None, 224, 224, 3)                9   ['data[0][0]']                   \n",
    " 03  zero_padding2d_18 (ZeroPadding2D)      (None, 230, 230, 3)                0   ['bn_data[0][0]']                \n",
    " 04  conv0 (Conv2D)                         (None, 112, 112, 64  9408)             ['zero_padding2d_18[0][0]']      \n",
    " 05  bn0 (BatchNormalization)               (None, 112, 112, 64  256)              ['conv0[0][0]']                  \n",
    " 06  relu0 (Activation)                     (None, 112, 112, 64  0)                ['bn0[0][0]']                    \n",
    " 07  zero_padding2d_19 (ZeroPadding2D)      (None, 114, 114, 64  0)                ['relu0[0][0]']                  \n",
    " 08  pooling0 (MaxPooling2D)                (None, 56, 56, 64)                 0   ['zero_padding2d_19[0][0]']      \n",
    " 09  stage1_unit1_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['pooling0[0][0]']               \n",
    " 10  stage1_unit1_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit1_bn1[0][0]']       \n",
    " 11  zero_padding2d_20 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit1_relu1[0][0]']     \n",
    " 12  stage1_unit1_conv1 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_20[0][0]']      \n",
    " 13  stage1_unit1_bn2 (BatchNormalization)  (None, 56, 56, 64)               256   ['stage1_unit1_conv1[0][0]']     \n",
    " 14  stage1_unit1_relu2 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit1_bn2[0][0]']       \n",
    " 15  zero_padding2d_21 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit1_relu2[0][0]']     \n",
    " 16  stage1_unit1_conv2 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_21[0][0]']      \n",
    " 17  stage1_unit1_sc (Conv2D)               (None, 56, 56, 64)              4096   ['stage1_unit1_relu1[0][0]']     \n",
    " 18  add_8 (Add)                            (None, 56, 56, 64)                 0   ['stage1_unit1_conv2[0][0]', 'stage1_unit1_sc[0][0]']\n",
    " 19  stage1_unit2_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['add_8[0][0]']                  \n",
    " 20  stage1_unit2_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit2_bn1[0][0]']       \n",
    " 21  zero_padding2d_22 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit2_relu1[0][0]']     \n",
    " 22  stage1_unit2_conv1 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_22[0][0]']      \n",
    " 23  stage1_unit2_bn2 (BatchNormalization)  (None, 56, 56, 64)               256   ['stage1_unit2_conv1[0][0]']     \n",
    " 24  stage1_unit2_relu2 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit2_bn2[0][0]']       \n",
    " 25  zero_padding2d_23 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit2_relu2[0][0]']     \n",
    " 26  stage1_unit2_conv2 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_23[0][0]']      \n",
    " 27  add_9 (Add)                            (None, 56, 56, 64)                 0   ['stage1_unit2_conv2[0][0]', 'add_8[0][0]']\n",
    " 28  stage2_unit1_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['add_9[0][0]']                  \n",
    " 29  stage2_unit1_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage2_unit1_bn1[0][0]']       \n",
    " 30  zero_padding2d_24 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage2_unit1_relu1[0][0]']     \n",
    " 31  stage2_unit1_conv1 (Conv2D)            (None, 28, 28, 128)            73728   ['zero_padding2d_24[0][0]']      \n",
    " 32  stage2_unit1_bn2 (BatchNormalization)  (None, 28, 28, 128)              512   ['stage2_unit1_conv1[0][0]']     \n",
    " 33  stage2_unit1_relu2 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit1_bn2[0][0]']       \n",
    " 34  zero_padding2d_25 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit1_relu2[0][0]']     \n",
    " 35  stage2_unit1_conv2 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_25[0][0]']      \n",
    " 36  stage2_unit1_sc (Conv2D)               (None, 28, 28, 128)             8192   ['stage2_unit1_relu1[0][0]']     \n",
    " 37  add_10 (Add)                           (None, 28, 28, 128)                0   ['stage2_unit1_conv2[0][0]', 'stage2_unit1_sc[0][0]']\n",
    " 38  stage2_unit2_bn1 (BatchNormalization)  (None, 28, 28, 128)              512   ['add_10[0][0]']                 \n",
    " 39  stage2_unit2_relu1 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit2_bn1[0][0]']       \n",
    " 40  zero_padding2d_26 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit2_relu1[0][0]']     \n",
    " 41  stage2_unit2_conv1 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_26[0][0]']      \n",
    " 42  stage2_unit2_bn2 (BatchNormalization)  (None, 28, 28, 128)              512   ['stage2_unit2_conv1[0][0]']     \n",
    " 43  stage2_unit2_relu2 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit2_bn2[0][0]']       \n",
    " 44  zero_padding2d_27 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit2_relu2[0][0]']     \n",
    " 45  stage2_unit2_conv2 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_27[0][0]']      \n",
    " 46  add_11 (Add)                           (None, 28, 28, 128)                0   ['stage2_unit2_conv2[0][0]', 'add_10[0][0]']\n",
    " 47  stage3_unit1_bn1 (BatchNormalization)  (None, 28, 28, 128)              512   ['add_11[0][0]']                 \n",
    " 48  stage3_unit1_relu1 (Activation)        (None, 28, 28, 128)                0   ['stage3_unit1_bn1[0][0]']       \n",
    " 49  zero_padding2d_28 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage3_unit1_relu1[0][0]']     \n",
    " 50  stage3_unit1_conv1 (Conv2D)            (None, 14, 14, 256)           294912   ['zero_padding2d_28[0][0]']      \n",
    " 51  stage3_unit1_bn2 (BatchNormalization)  (None, 14, 14, 256)             1024   ['stage3_unit1_conv1[0][0]']     \n",
    " 52  stage3_unit1_relu2 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit1_bn2[0][0]']       \n",
    " 53  zero_padding2d_29 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit1_relu2[0][0]']     \n",
    " 54  stage3_unit1_conv2 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_29[0][0]']      \n",
    " 55  stage3_unit1_sc (Conv2D)               (None, 14, 14, 256)            32768   ['stage3_unit1_relu1[0][0]']     \n",
    " 56  add_12 (Add)                           (None, 14, 14, 256)                0   ['stage3_unit1_conv2[0][0]', 'stage3_unit1_sc[0][0]']\n",
    " 57  stage3_unit2_bn1 (BatchNormalization)  (None, 14, 14, 256)             1024   ['add_12[0][0]']                 \n",
    " 58  stage3_unit2_relu1 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit2_bn1[0][0]']       \n",
    " 59  zero_padding2d_30 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit2_relu1[0][0]']     \n",
    " 60  stage3_unit2_conv1 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_30[0][0]']      \n",
    " 61  stage3_unit2_bn2 (BatchNormalization)  (None, 14, 14, 256)             1024   ['stage3_unit2_conv1[0][0]']     \n",
    " 62  stage3_unit2_relu2 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit2_bn2[0][0]']       \n",
    " 63  zero_padding2d_31 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit2_relu2[0][0]']     \n",
    " 64  stage3_unit2_conv2 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_31[0][0]']      \n",
    " 65  add_13 (Add)                           (None, 14, 14, 256)                0   ['stage3_unit2_conv2[0][0]', 'add_12[0][0]']\n",
    " 66  stage4_unit1_bn1 (BatchNormalization)  (None, 14, 14, 256)             1024   ['add_13[0][0]']                 \n",
    " 67  stage4_unit1_relu1 (Activation)        (None, 14, 14, 256)                0   ['stage4_unit1_bn1[0][0]']       \n",
    " 68  zero_padding2d_32 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage4_unit1_relu1[0][0]']     \n",
    " 69  stage4_unit1_conv1 (Conv2D)            (None, 7, 7, 512)            1179648   ['zero_padding2d_32[0][0]']      \n",
    " 70  stage4_unit1_bn2 (BatchNormalization)  (None, 7, 7, 512)               2048   ['stage4_unit1_conv1[0][0]']     \n",
    " 71  stage4_unit1_relu2 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit1_bn2[0][0]']       \n",
    " 72  zero_padding2d_33 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit1_relu2[0][0]']     \n",
    " 73  stage4_unit1_conv2 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_33[0][0]']      \n",
    " 74  stage4_unit1_sc (Conv2D)               (None, 7, 7, 512)             131072   ['stage4_unit1_relu1[0][0]']     \n",
    " 75  add_14 (Add)                           (None, 7, 7, 512)                  0   ['stage4_unit1_conv2[0][0]', 'stage4_unit1_sc[0][0]']\n",
    " 76  stage4_unit2_bn1 (BatchNormalization)  (None, 7, 7, 512)               2048   ['add_14[0][0]']                 \n",
    " 77  stage4_unit2_relu1 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit2_bn1[0][0]']       \n",
    " 78  zero_padding2d_34 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit2_relu1[0][0]']     \n",
    " 79  stage4_unit2_conv1 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_34[0][0]']      \n",
    " 80  stage4_unit2_bn2 (BatchNormalization)  (None, 7, 7, 512)               2048   ['stage4_unit2_conv1[0][0]']     \n",
    " 81  stage4_unit2_relu2 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit2_bn2[0][0]']       \n",
    " 82  zero_padding2d_35 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit2_relu2[0][0]']     \n",
    " 83  stage4_unit2_conv2 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_35[0][0]']      \n",
    " 84  add_15 (Add)                           (None, 7, 7, 512)                  0   ['stage4_unit2_conv2[0][0]', 'add_14[0][0]']\n",
    " 85  bn1 (BatchNormalization)               (None, 7, 7, 512)               2048   ['add_15[0][0]']                 \n",
    " 86  relu1 (Activation)                     (None, 7, 7, 512)                  0   ['bn1[0][0]']                    \n",
    " 87  pool1 (GlobalAveragePooling2D)         (None, 512)                        0   ['relu1[0][0]']                  \n",
    " 88  predictions (Dense)                    (None, 3)                       1539   ['pool1[0][0]']  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
