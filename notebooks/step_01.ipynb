{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7682453f",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Traducción a Python de **step_01_train_tumor_normal_classifier_final_crossval.m**\n",
    "\n",
    "Comentarios:\n",
    "\n",
    "- En el código original se usaba la resolución de la red de MatLab (224x224), https://www.mathworks.com/help/deeplearning/ug/pretrained-convolutional-neural-networks.html. Manteniendo el tamaño original de la red, se puede hacer transfer learning.\n",
    "- Se usa ResNet18 de la librería classification_models (https://github.com/qubvel/classification_models)\n",
    "- Se dejan liberadas las 20 últimas capas, como hace el script de MatLab Coincide con el último cambio de tamaño de las salidas intermedias.\n",
    "- Se hace validación cruzada con k-fold para $k=5$. En el armado de los datasets de entrenamiento y test, Kather *et al.* usan uno de los $k$ subconjuntos para entrenamiento y los 4 restantes para test. En este código se invierten las cantidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a8cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator  \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "# Se tuvo que cambiar varios imports en el código de classification_models porque \n",
    "# (parece que) apuntaban a una versión viejas de Keras o tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e540c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_inputPath_str = \"/home/ag/Documents/Kather/NCT_512_3CL_dataset\" # parent folder for the data set\n",
    "image_inputPath = pathlib.Path(image_inputPath_str)\n",
    "\n",
    "loadPreviousProgress = False # continue where you stopped before\n",
    "currFn = 'classi3xval' # current filename for saving log files\n",
    "\n",
    "hyperparam = {}\n",
    "hyperparam[\"InitialLearnRate\"] = 5e-6      # initial learning rate\n",
    "hyperparam[\"L2Regularization\"] = 1e-4      # optimization L2 constraint\n",
    "hyperparam[\"MiniBatchSize\"] = 64           # mini batch size, limited by GPU RAM, default 100 on Titan, 500 on P6000\n",
    "hyperparam[\"MaxEpochs\"] = 5                # max. epochs for training, default 15\n",
    "hyperparam[\"hotLayers\"] = 20               # how many layers from the end are not frozen\n",
    "hyperparam[\"learnRateFactor\"] = 2          # learning rate factor for rewired layers\n",
    "hyperparam[\"ExecutionEnvironment\"] = 'gpu' # environment for training and classification\n",
    "hyperparam[\"PixelRangeShear\"] = 5;         # max. xy translation (in pixels) for image augmenter\n",
    "allHyperparam = list(hyperparam.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96aba24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class TUMSTU: 4000 files, min width: 512, max width: 512, min height: 512, max height: 512\n",
      "Class STRMUS: 4000 files, min width: 512, max width: 512, min height: 512, max height: 512\n",
      "Class ADIMUC: 3977 files, min width: 512, max width: 512, min height: 512, max height: 512\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "# Chequeo de cantidad de archivos y tamaño de imágenes\n",
    "\n",
    "for im_class in os.listdir(image_inputPath):\n",
    "    dir_width = []\n",
    "    dir_height = []\n",
    "    file_count = 0\n",
    "    for im_file in os.listdir(str(image_inputPath) + \"/\" + im_class):\n",
    "        file_count = file_count + 1\n",
    "        im = PIL.Image.open(str(image_inputPath) + \"/\" + im_class + \"/\" + im_file)\n",
    "        width, height = im.size\n",
    "        dir_width.append(width)\n",
    "        dir_height.append(height)\n",
    "    print(\"Class \" + im_class + \": \" + str(file_count) + \" files, min width: \" \n",
    "          + str(min(dir_width)) + \", max width: \" + str(max(dir_width)) + \", min height: \" \n",
    "          + str(min(dir_height)) + \", max height: \" + str(max(dir_height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c05dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11977 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 12:52:37.163364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:37.233178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:37.233453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:37.235305: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-24 12:52:37.236322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:37.236557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:37.236655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:38.107771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:38.107912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:38.108011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-24 12:52:38.108640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11037 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  READ ALL IMAGES and prepare for cross validation\n",
    "\n",
    "img_height = 224 # 512\n",
    "img_width = 224 # 512\n",
    "\n",
    "allImages = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_inputPath,\n",
    "  labels='inferred',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "#   batch_size=hyperparam[\"MiniBatchSize\"]\n",
    "  batch_size=None, # No hay batch\n",
    "  label_mode='categorical'\n",
    "  )\n",
    "allImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bc3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n",
      "<class 'list'>\n",
      "10\n",
      "<class 'tuple'>\n",
      "<class 'numpy.ndarray'>\n",
      "(224, 224, 3)\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "\n",
    "print(type(allImages))\n",
    "b = allImages.take(10)\n",
    "print(type(b))\n",
    "a = list(b.as_numpy_iterator())\n",
    "\n",
    "print(type(a))\n",
    "print(len(a))\n",
    "print(type(a[0]))\n",
    "print(type(a[0][0]))\n",
    "print(a[0][0].shape)\n",
    "print(a[0][1].shape)\n",
    "print(type(a[0][1]))\n",
    "print(a[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bbf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "class_names = allImages.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbb74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADIMUC', 'STRMUS', 'TUMSTU']\n"
     ]
    }
   ],
   "source": [
    "# NO ES PARTE DEL SCRIPT\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40c80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_factor = hyperparam[\"PixelRangeShear\"]/224\n",
    "flip_layer = layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "translation_layer = layers.RandomTranslation(height_factor=hw_factor, width_factor=hw_factor)\n",
    "resizing_layer = layers.Resizing(img_height, img_width)\n",
    "\n",
    "allImages_r = allImages.map(lambda x, y: (resizing_layer(x), y))\n",
    "\n",
    "def preprocess(images, labels):\n",
    "  return preprocess_input(images), labels\n",
    "\n",
    "allImages_prep = allImages_r.map(preprocess)\n",
    "\n",
    "def expand_d(images, labels):\n",
    "     return tf.expand_dims(images, axis=0), tf.expand_dims(labels, axis=0)\n",
    "\n",
    "allImages_prep_exp = allImages_prep.map(expand_d)\n",
    "\n",
    "sub1 = allImages_prep_exp.shard(num_shards=5, index=0)\n",
    "sub2 = allImages_prep_exp.shard(num_shards=5, index=1)\n",
    "sub3 = allImages_prep_exp.shard(num_shards=5, index=2)\n",
    "sub4 = allImages_prep_exp.shard(num_shards=5, index=3)\n",
    "sub5 = allImages_prep_exp.shard(num_shards=5, index=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6a47e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------Entrenamiento para k = 1 --------------\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 12:52:49.697213: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-03-24 12:52:50.994749: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9581/9581 [==============================] - 159s 15ms/step - loss: 0.2285 - accuracy: 0.9217 - val_loss: 0.2888 - val_accuracy: 0.8902\n",
      "Epoch 2/5\n",
      "9581/9581 [==============================] - 120s 13ms/step - loss: 0.1032 - accuracy: 0.9715 - val_loss: 0.3152 - val_accuracy: 0.8944\n",
      "Epoch 3/5\n",
      "9581/9581 [==============================] - 121s 13ms/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.4664 - val_accuracy: 0.7884\n",
      "Epoch 4/5\n",
      "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.3449 - val_accuracy: 0.8986\n",
      "Epoch 5/5\n",
      "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0566 - accuracy: 0.9849 - val_loss: 0.1547 - val_accuracy: 0.9741\n",
      "\n",
      "--------------Entrenamiento para k = 2 --------------\n",
      "\n",
      "Epoch 1/5\n",
      "9581/9581 [==============================] - 115s 11ms/step - loss: 0.2326 - accuracy: 0.9192 - val_loss: 0.5439 - val_accuracy: 0.8264\n",
      "Epoch 2/5\n",
      "9581/9581 [==============================] - 86s 9ms/step - loss: 0.0890 - accuracy: 0.9763 - val_loss: 0.2247 - val_accuracy: 0.9265\n",
      "Epoch 3/5\n",
      "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.3349 - val_accuracy: 0.9011\n",
      "Epoch 4/5\n",
      "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0377 - accuracy: 0.9909 - val_loss: 0.2890 - val_accuracy: 0.9240\n",
      "Epoch 5/5\n",
      "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.4071 - val_accuracy: 0.8756\n",
      "\n",
      "--------------Entrenamiento para k = 3 --------------\n",
      "\n",
      "Epoch 1/5\n",
      "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2544 - accuracy: 0.9092 - val_loss: 3.9616 - val_accuracy: 0.6033\n",
      "Epoch 2/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0737 - accuracy: 0.9795 - val_loss: 0.4025 - val_accuracy: 0.8576\n",
      "Epoch 3/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.4569 - val_accuracy: 0.7971\n",
      "Epoch 4/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 1.1441 - val_accuracy: 0.6372\n",
      "Epoch 5/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.2920 - val_accuracy: 0.9152\n",
      "\n",
      "--------------Entrenamiento para k = 4 --------------\n",
      "\n",
      "Epoch 1/5\n",
      "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2081 - accuracy: 0.9320 - val_loss: 1.8176 - val_accuracy: 0.4747\n",
      "Epoch 2/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0752 - accuracy: 0.9795 - val_loss: 1.0992 - val_accuracy: 0.7023\n",
      "Epoch 3/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.3079 - val_accuracy: 0.8985\n",
      "Epoch 4/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.4832 - val_accuracy: 0.8234\n",
      "Epoch 5/5\n",
      "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.6125 - val_accuracy: 0.7566\n",
      "\n",
      "--------------Entrenamiento para k = 5 --------------\n",
      "\n",
      "Epoch 1/5\n",
      "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2213 - accuracy: 0.9224 - val_loss: 0.3530 - val_accuracy: 0.8894\n",
      "Epoch 2/5\n",
      "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.2126 - val_accuracy: 0.9165\n",
      "Epoch 3/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.6642 - val_accuracy: 0.7937\n",
      "Epoch 4/5\n",
      "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 0.4132 - val_accuracy: 0.8501\n",
      "Epoch 5/5\n",
      "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 0.1960 - val_accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "for idx in range(1, 6):\n",
    "    print(\"\\n--------------Entrenamiento para k = \" + str(idx) + \" --------------\\n\")\n",
    "    if idx == 1:\n",
    "        trainSet = sub2.concatenate(sub3).concatenate(sub4).concatenate(sub5)\n",
    "        testSet = sub1\n",
    "    elif idx == 2:\n",
    "        trainSet = sub1.concatenate(sub3).concatenate(sub4).concatenate(sub5)\n",
    "        testSet = sub2\n",
    "    elif idx == 3:\n",
    "        trainSet = sub1.concatenate(sub2).concatenate(sub4).concatenate(sub5)\n",
    "        testSet = sub3\n",
    "    elif idx == 4:\n",
    "        trainSet = sub1.concatenate(sub2).concatenate(sub3).concatenate(sub5)\n",
    "        testSet = sub4\n",
    "    elif idx == 5:\n",
    "        trainSet = sub1.concatenate(sub2).concatenate(sub3).concatenate(sub4)\n",
    "        testSet = sub5\n",
    "\n",
    "    trainSet_cache = trainSet.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    testSet_cache = testSet.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    trainSet_cache_da = trainSet_cache.map(lambda x, y: (flip_layer(x), y))\n",
    "    trainSet_cache_da = trainSet_cache_da.map(lambda x, y: (translation_layer(x), y))\n",
    "    \n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    model_orig = ResNet18((224, 224, 3), weights='imagenet')\n",
    "    new_layer_output = Dense(len(class_names), activation='softmax', name='predictions')\n",
    "    model = Model(model_orig.input, new_layer_output(model_orig.layers[-3].output))\n",
    "#     model.summary()\n",
    "    ldx = 0\n",
    "    for layer in model.layers:\n",
    "        ldx = ldx + 1\n",
    "        if ldx < 69:\n",
    "            layer.trainable = False\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    ep=5\n",
    "    model.fit(trainSet_cache_da, validation_data=testSet_cache, epochs=ep, validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964172ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALIDA:\n",
    "\n",
    "--------------Entrenamiento para k = 1 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "\n",
    "2022-03-24 12:52:49.697213: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
    "2022-03-24 12:52:50.994749: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
    "\n",
    "9581/9581 [==============================] - 159s 15ms/step - loss: 0.2285 - accuracy: 0.9217 - val_loss: 0.2888 - val_accuracy: 0.8902\n",
    "Epoch 2/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.1032 - accuracy: 0.9715 - val_loss: 0.3152 - val_accuracy: 0.8944\n",
    "Epoch 3/5\n",
    "9581/9581 [==============================] - 121s 13ms/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.4664 - val_accuracy: 0.7884\n",
    "Epoch 4/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.3449 - val_accuracy: 0.8986\n",
    "Epoch 5/5\n",
    "9581/9581 [==============================] - 120s 13ms/step - loss: 0.0566 - accuracy: 0.9849 - val_loss: 0.1547 - val_accuracy: 0.9741\n",
    "\n",
    "--------------Entrenamiento para k = 2 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9581/9581 [==============================] - 115s 11ms/step - loss: 0.2326 - accuracy: 0.9192 - val_loss: 0.5439 - val_accuracy: 0.8264\n",
    "Epoch 2/5\n",
    "9581/9581 [==============================] - 86s 9ms/step - loss: 0.0890 - accuracy: 0.9763 - val_loss: 0.2247 - val_accuracy: 0.9265\n",
    "Epoch 3/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.3349 - val_accuracy: 0.9011\n",
    "Epoch 4/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0377 - accuracy: 0.9909 - val_loss: 0.2890 - val_accuracy: 0.9240\n",
    "Epoch 5/5\n",
    "9581/9581 [==============================] - 85s 9ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.4071 - val_accuracy: 0.8756\n",
    "\n",
    "--------------Entrenamiento para k = 3 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2544 - accuracy: 0.9092 - val_loss: 3.9616 - val_accuracy: 0.6033\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0737 - accuracy: 0.9795 - val_loss: 0.4025 - val_accuracy: 0.8576\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.4569 - val_accuracy: 0.7971\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 1.1441 - val_accuracy: 0.6372\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.2920 - val_accuracy: 0.9152\n",
    "\n",
    "--------------Entrenamiento para k = 4 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2081 - accuracy: 0.9320 - val_loss: 1.8176 - val_accuracy: 0.4747\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0752 - accuracy: 0.9795 - val_loss: 1.0992 - val_accuracy: 0.7023\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.3079 - val_accuracy: 0.8985\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.4832 - val_accuracy: 0.8234\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.6125 - val_accuracy: 0.7566\n",
    "\n",
    "--------------Entrenamiento para k = 5 --------------\n",
    "\n",
    "Epoch 1/5\n",
    "9582/9582 [==============================] - 115s 11ms/step - loss: 0.2213 - accuracy: 0.9224 - val_loss: 0.3530 - val_accuracy: 0.8894\n",
    "Epoch 2/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.2126 - val_accuracy: 0.9165\n",
    "Epoch 3/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.6642 - val_accuracy: 0.7937\n",
    "Epoch 4/5\n",
    "9582/9582 [==============================] - 85s 9ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 0.4132 - val_accuracy: 0.8501\n",
    "Epoch 5/5\n",
    "9582/9582 [==============================] - 86s 9ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 0.1960 - val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8caca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00547cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c7864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab12a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27287e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4bab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689e35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4f14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aab5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3350543",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ==================================================================================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "__________________________________________________________________________________________________\n",
    "    Layer (type)                            Output Shape               Param #     Connected to                     \n",
    "   ==================================================================================================\n",
    " 01  data (InputLayer)                     [(None, 224, 224, 3  0)]                []                               \n",
    " 02  bn_data (BatchNormalization)           (None, 224, 224, 3)                9   ['data[0][0]']                   \n",
    " 03  zero_padding2d_18 (ZeroPadding2D)      (None, 230, 230, 3)                0   ['bn_data[0][0]']                \n",
    " 04  conv0 (Conv2D)                         (None, 112, 112, 64  9408)             ['zero_padding2d_18[0][0]']      \n",
    " 05  bn0 (BatchNormalization)               (None, 112, 112, 64  256)              ['conv0[0][0]']                  \n",
    " 06  relu0 (Activation)                     (None, 112, 112, 64  0)                ['bn0[0][0]']                    \n",
    " 07  zero_padding2d_19 (ZeroPadding2D)      (None, 114, 114, 64  0)                ['relu0[0][0]']                  \n",
    " 08  pooling0 (MaxPooling2D)                (None, 56, 56, 64)                 0   ['zero_padding2d_19[0][0]']      \n",
    " 09  stage1_unit1_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['pooling0[0][0]']               \n",
    " 10  stage1_unit1_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit1_bn1[0][0]']       \n",
    " 11  zero_padding2d_20 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit1_relu1[0][0]']     \n",
    " 12  stage1_unit1_conv1 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_20[0][0]']      \n",
    " 13  stage1_unit1_bn2 (BatchNormalization)  (None, 56, 56, 64)               256   ['stage1_unit1_conv1[0][0]']     \n",
    " 14  stage1_unit1_relu2 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit1_bn2[0][0]']       \n",
    " 15  zero_padding2d_21 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit1_relu2[0][0]']     \n",
    " 16  stage1_unit1_conv2 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_21[0][0]']      \n",
    " 17  stage1_unit1_sc (Conv2D)               (None, 56, 56, 64)              4096   ['stage1_unit1_relu1[0][0]']     \n",
    " 18  add_8 (Add)                            (None, 56, 56, 64)                 0   ['stage1_unit1_conv2[0][0]', 'stage1_unit1_sc[0][0]']\n",
    " 19  stage1_unit2_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['add_8[0][0]']                  \n",
    " 20  stage1_unit2_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit2_bn1[0][0]']       \n",
    " 21  zero_padding2d_22 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit2_relu1[0][0]']     \n",
    " 22  stage1_unit2_conv1 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_22[0][0]']      \n",
    " 23  stage1_unit2_bn2 (BatchNormalization)  (None, 56, 56, 64)               256   ['stage1_unit2_conv1[0][0]']     \n",
    " 24  stage1_unit2_relu2 (Activation)        (None, 56, 56, 64)                 0   ['stage1_unit2_bn2[0][0]']       \n",
    " 25  zero_padding2d_23 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage1_unit2_relu2[0][0]']     \n",
    " 26  stage1_unit2_conv2 (Conv2D)            (None, 56, 56, 64)             36864   ['zero_padding2d_23[0][0]']      \n",
    " 27  add_9 (Add)                            (None, 56, 56, 64)                 0   ['stage1_unit2_conv2[0][0]', 'add_8[0][0]']\n",
    " 28  stage2_unit1_bn1 (BatchNormalization)  (None, 56, 56, 64)               256   ['add_9[0][0]']                  \n",
    " 29  stage2_unit1_relu1 (Activation)        (None, 56, 56, 64)                 0   ['stage2_unit1_bn1[0][0]']       \n",
    " 30  zero_padding2d_24 (ZeroPadding2D)      (None, 58, 58, 64)                 0   ['stage2_unit1_relu1[0][0]']     \n",
    " 31  stage2_unit1_conv1 (Conv2D)            (None, 28, 28, 128)            73728   ['zero_padding2d_24[0][0]']      \n",
    " 32  stage2_unit1_bn2 (BatchNormalization)  (None, 28, 28, 128)              512   ['stage2_unit1_conv1[0][0]']     \n",
    " 33  stage2_unit1_relu2 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit1_bn2[0][0]']       \n",
    " 34  zero_padding2d_25 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit1_relu2[0][0]']     \n",
    " 35  stage2_unit1_conv2 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_25[0][0]']      \n",
    " 36  stage2_unit1_sc (Conv2D)               (None, 28, 28, 128)             8192   ['stage2_unit1_relu1[0][0]']     \n",
    " 37  add_10 (Add)                           (None, 28, 28, 128)                0   ['stage2_unit1_conv2[0][0]', 'stage2_unit1_sc[0][0]']\n",
    " 38  stage2_unit2_bn1 (BatchNormalization)  (None, 28, 28, 128)              512   ['add_10[0][0]']                 \n",
    " 39  stage2_unit2_relu1 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit2_bn1[0][0]']       \n",
    " 40  zero_padding2d_26 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit2_relu1[0][0]']     \n",
    " 41  stage2_unit2_conv1 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_26[0][0]']      \n",
    " 42  stage2_unit2_bn2 (BatchNormalization)  (None, 28, 28, 128)              512   ['stage2_unit2_conv1[0][0]']     \n",
    " 43  stage2_unit2_relu2 (Activation)        (None, 28, 28, 128)                0   ['stage2_unit2_bn2[0][0]']       \n",
    " 44  zero_padding2d_27 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage2_unit2_relu2[0][0]']     \n",
    " 45  stage2_unit2_conv2 (Conv2D)            (None, 28, 28, 128)           147456   ['zero_padding2d_27[0][0]']      \n",
    " 46  add_11 (Add)                           (None, 28, 28, 128)                0   ['stage2_unit2_conv2[0][0]', 'add_10[0][0]']\n",
    " 47  stage3_unit1_bn1 (BatchNormalization)  (None, 28, 28, 128)              512   ['add_11[0][0]']                 \n",
    " 48  stage3_unit1_relu1 (Activation)        (None, 28, 28, 128)                0   ['stage3_unit1_bn1[0][0]']       \n",
    " 49  zero_padding2d_28 (ZeroPadding2D)      (None, 30, 30, 128)                0   ['stage3_unit1_relu1[0][0]']     \n",
    " 50  stage3_unit1_conv1 (Conv2D)            (None, 14, 14, 256)           294912   ['zero_padding2d_28[0][0]']      \n",
    " 51  stage3_unit1_bn2 (BatchNormalization)  (None, 14, 14, 256)             1024   ['stage3_unit1_conv1[0][0]']     \n",
    " 52  stage3_unit1_relu2 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit1_bn2[0][0]']       \n",
    " 53  zero_padding2d_29 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit1_relu2[0][0]']     \n",
    " 54  stage3_unit1_conv2 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_29[0][0]']      \n",
    " 55  stage3_unit1_sc (Conv2D)               (None, 14, 14, 256)            32768   ['stage3_unit1_relu1[0][0]']     \n",
    " 56  add_12 (Add)                           (None, 14, 14, 256)                0   ['stage3_unit1_conv2[0][0]', 'stage3_unit1_sc[0][0]']\n",
    " 57  stage3_unit2_bn1 (BatchNormalization)  (None, 14, 14, 256)             1024   ['add_12[0][0]']                 \n",
    " 58  stage3_unit2_relu1 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit2_bn1[0][0]']       \n",
    " 59  zero_padding2d_30 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit2_relu1[0][0]']     \n",
    " 60  stage3_unit2_conv1 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_30[0][0]']      \n",
    " 61  stage3_unit2_bn2 (BatchNormalization)  (None, 14, 14, 256)             1024   ['stage3_unit2_conv1[0][0]']     \n",
    " 62  stage3_unit2_relu2 (Activation)        (None, 14, 14, 256)                0   ['stage3_unit2_bn2[0][0]']       \n",
    " 63  zero_padding2d_31 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage3_unit2_relu2[0][0]']     \n",
    " 64  stage3_unit2_conv2 (Conv2D)            (None, 14, 14, 256)           589824   ['zero_padding2d_31[0][0]']      \n",
    " 65  add_13 (Add)                           (None, 14, 14, 256)                0   ['stage3_unit2_conv2[0][0]', 'add_12[0][0]']\n",
    " 66  stage4_unit1_bn1 (BatchNormalization)  (None, 14, 14, 256)             1024   ['add_13[0][0]']                 \n",
    " 67  stage4_unit1_relu1 (Activation)        (None, 14, 14, 256)                0   ['stage4_unit1_bn1[0][0]']       \n",
    " 68  zero_padding2d_32 (ZeroPadding2D)      (None, 16, 16, 256)                0   ['stage4_unit1_relu1[0][0]']     \n",
    " 69  stage4_unit1_conv1 (Conv2D)            (None, 7, 7, 512)            1179648   ['zero_padding2d_32[0][0]']      \n",
    " 70  stage4_unit1_bn2 (BatchNormalization)  (None, 7, 7, 512)               2048   ['stage4_unit1_conv1[0][0]']     \n",
    " 71  stage4_unit1_relu2 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit1_bn2[0][0]']       \n",
    " 72  zero_padding2d_33 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit1_relu2[0][0]']     \n",
    " 73  stage4_unit1_conv2 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_33[0][0]']      \n",
    " 74  stage4_unit1_sc (Conv2D)               (None, 7, 7, 512)             131072   ['stage4_unit1_relu1[0][0]']     \n",
    " 75  add_14 (Add)                           (None, 7, 7, 512)                  0   ['stage4_unit1_conv2[0][0]', 'stage4_unit1_sc[0][0]']\n",
    " 76  stage4_unit2_bn1 (BatchNormalization)  (None, 7, 7, 512)               2048   ['add_14[0][0]']                 \n",
    " 77  stage4_unit2_relu1 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit2_bn1[0][0]']       \n",
    " 78  zero_padding2d_34 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit2_relu1[0][0]']     \n",
    " 79  stage4_unit2_conv1 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_34[0][0]']      \n",
    " 80  stage4_unit2_bn2 (BatchNormalization)  (None, 7, 7, 512)               2048   ['stage4_unit2_conv1[0][0]']     \n",
    " 81  stage4_unit2_relu2 (Activation)        (None, 7, 7, 512)                  0   ['stage4_unit2_bn2[0][0]']       \n",
    " 82  zero_padding2d_35 (ZeroPadding2D)      (None, 9, 9, 512)                  0   ['stage4_unit2_relu2[0][0]']     \n",
    " 83  stage4_unit2_conv2 (Conv2D)            (None, 7, 7, 512)            2359296   ['zero_padding2d_35[0][0]']      \n",
    " 84  add_15 (Add)                           (None, 7, 7, 512)                  0   ['stage4_unit2_conv2[0][0]', 'add_14[0][0]']\n",
    " 85  bn1 (BatchNormalization)               (None, 7, 7, 512)               2048   ['add_15[0][0]']                 \n",
    " 86  relu1 (Activation)                     (None, 7, 7, 512)                  0   ['bn1[0][0]']                    \n",
    " 87  pool1 (GlobalAveragePooling2D)         (None, 512)                        0   ['relu1[0][0]']                  \n",
    " 88  predictions (Dense)                    (None, 3)                       1539   ['pool1[0][0]']  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
